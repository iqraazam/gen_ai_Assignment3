{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8180b0ff",
   "metadata": {},
   "source": [
    "Part 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Step 1: Load IMDb dataset (subset with 5000 samples)\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Limit the data to 3000 train and 2000 test samples\n",
    "small_dataset = DatasetDict({\n",
    "    'train': dataset['train'].shuffle(seed=42).select(range(3000)),\n",
    "    'test': dataset['test'].shuffle(seed=42).select(range(2000))\n",
    "})\n",
    "\n",
    "# Step 2: Load Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Step 3: Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",      # Pad to max_length\n",
    "        truncation=True,           # Truncate if too long\n",
    "        max_length=512             # Optional: Set max length to 512 (Roberta limit)\n",
    "    )\n",
    "\n",
    "# Apply the tokenizer to the dataset\n",
    "tokenized_datasets = small_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# For training purposes, remove columns not used by the model\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets.set_format(\"torch\")  # For PyTorch\n",
    "\n",
    "# Quick check\n",
    "print(tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237fd49c",
   "metadata": {},
   "source": [
    "Part 2 Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0655d8",
   "metadata": {},
   "source": [
    "Part 3 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5cd20d",
   "metadata": {},
   "source": [
    "Method 1: Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9074143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "# Function to measure GPU memory usage\n",
    "def get_gpu_memory_usage():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)  # Assuming we're using GPU 0\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    return info.used / 1024**2  # Return in MB\n",
    "\n",
    "# Load dataset\n",
    "def load_imdb_dataset():\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    # Ensure we only use 3000 samples for training and 2000 for testing\n",
    "    train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(3000))\n",
    "    test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(2000))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "# Compute metrics function for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "def run_full_finetuning():\n",
    "    method_name = \"full_finetuning\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Running Method 1: Full Fine-Tuning\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    \n",
    "    # Load and prepare datasets\n",
    "    train_dataset, test_dataset = load_imdb_dataset()\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_dataset.map(\n",
    "        lambda examples: tokenize_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    tokenized_test = test_dataset.map(\n",
    "        lambda examples: tokenize_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"roberta-base\",\n",
    "        num_labels=2  # Binary classification: positive or negative\n",
    "    )\n",
    "    \n",
    "    # Setup trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"output/{method_name}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",  # Disable wandb, tensorboard etc.\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    max_gpu_memory = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(int(training_args.num_train_epochs)):\n",
    "            trainer.train()\n",
    "            \n",
    "            # Record GPU memory usage\n",
    "            if torch.cuda.is_available():\n",
    "                current_memory = get_gpu_memory_usage()\n",
    "                max_gpu_memory = max(max_gpu_memory, current_memory)\n",
    "                print(f\"GPU Memory after epoch {epoch+1}: {current_memory:.2f} MB\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation Results: {eval_results}\")\n",
    "    \n",
    "    # Record and save statistics\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    stats = {\n",
    "        \"method\": method_name,\n",
    "        \"training_time\": training_time,\n",
    "        \"trainable_parameters\": trainable_params,\n",
    "        \"total_parameters\": total_params,\n",
    "        \"trainable_percentage\": (trainable_params / total_params) * 100,\n",
    "        \"accuracy\": eval_results[\"eval_accuracy\"]\n",
    "    }\n",
    "    \n",
    "    if max_gpu_memory > 0:\n",
    "        stats[\"max_gpu_memory_mb\"] = max_gpu_memory\n",
    "    \n",
    "    print(f\"\\n{method_name} Statistics:\")\n",
    "    print(f\"  Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"  Total Parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable Parameters %: {stats['trainable_percentage']:.2f}%\")\n",
    "    print(f\"  Accuracy: {stats['accuracy']:.4f}\")\n",
    "    if max_gpu_memory > 0:\n",
    "        print(f\"  Max GPU Memory Usage: {max_gpu_memory:.2f} MB\")\n",
    "    \n",
    "    # Save statistics and results\n",
    "    os.makedirs(\"stats\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # Save statistics\n",
    "    with open(f\"stats/{method_name}_stats.txt\", \"w\") as f:\n",
    "        for key, value in stats.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    # Save evaluation results\n",
    "    with open(f\"results/{method_name}_eval.txt\", \"w\") as f:\n",
    "        for key, value in eval_results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    return model, eval_results, stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_finetuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ba3ea",
   "metadata": {},
   "source": [
    "Method 2: LoRA Fine-Tuning using PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "# Function to measure GPU memory usage\n",
    "def get_gpu_memory_usage():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)  # Assuming we're using GPU 0\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    return info.used / 1024**2  # Return in MB\n",
    "\n",
    "# Load dataset\n",
    "def load_imdb_dataset():\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    # Ensure we only use 3000 samples for training and 2000 for testing\n",
    "    train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(3000))\n",
    "    test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(2000))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "# Compute metrics function for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "def run_lora_finetuning():\n",
    "    method_name = \"lora_finetuning\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Running Method 2: LoRA Fine-Tuning using PEFT\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    \n",
    "    # Load and prepare datasets\n",
    "    train_dataset, test_dataset = load_imdb_dataset()\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_dataset.map(\n",
    "        lambda examples: tokenize_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    tokenized_test = test_dataset.map(\n",
    "        lambda examples: tokenize_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    # Load the base model\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"roberta-base\",\n",
    "        num_labels=2  # Binary classification: positive or negative\n",
    "    )\n",
    "    \n",
    "    # Define LoRA configuration\n",
    "    lora_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        r=8,  # Rank\n",
    "        lora_alpha=16,  # Alpha scaling\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"query\", \"key\", \"value\"],  # Target attention modules\n",
    "    )\n",
    "    \n",
    "    # Apply LoRA adapters to the model\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    print(\"Model with LoRA adapters:\")\n",
    "    model.print_trainable_parameters()  # Print % of trainable parameters\n",
    "    \n",
    "    # Setup trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"output/{method_name}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",  # Disable wandb, tensorboard etc.\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    max_gpu_memory = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(int(training_args.num_train_epochs)):\n",
    "            trainer.train()\n",
    "            \n",
    "            # Record GPU memory usage\n",
    "            if torch.cuda.is_available():\n",
    "                current_memory = get_gpu_memory_usage()\n",
    "                max_gpu_memory = max(max_gpu_memory, current_memory)\n",
    "                print(f\"GPU Memory after epoch {epoch+1}: {current_memory:.2f} MB\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation Results: {eval_results}\")\n",
    "    \n",
    "    # Record and save statistics\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    stats = {\n",
    "        \"method\": method_name,\n",
    "        \"training_time\": training_time,\n",
    "        \"trainable_parameters\": trainable_params,\n",
    "        \"total_parameters\": total_params,\n",
    "        \"trainable_percentage\": (trainable_params / total_params) * 100,\n",
    "        \"accuracy\": eval_results[\"eval_accuracy\"]\n",
    "    }\n",
    "    \n",
    "    if max_gpu_memory > 0:\n",
    "        stats[\"max_gpu_memory_mb\"] = max_gpu_memory\n",
    "    \n",
    "    print(f\"\\n{method_name} Statistics:\")\n",
    "    print(f\"  Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"  Total Parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable Parameters %: {stats['trainable_percentage']:.2f}%\")\n",
    "    print(f\"  Accuracy: {stats['accuracy']:.4f}\")\n",
    "    if max_gpu_memory > 0:\n",
    "        print(f\"  Max GPU Memory Usage: {max_gpu_memory:.2f} MB\")\n",
    "    \n",
    "    # Save statistics and results\n",
    "    os.makedirs(\"stats\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # Save statistics\n",
    "    with open(f\"stats/{method_name}_stats.txt\", \"w\") as f:\n",
    "        for key, value in stats.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    # Save evaluation results\n",
    "    with open(f\"results/{method_name}_eval.txt\", \"w\") as f:\n",
    "        for key, value in eval_results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    return model, eval_results, stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_lora_finetuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca53a990",
   "metadata": {},
   "source": [
    "Method 3: QLoRA Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01341a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Function to measure GPU memory usage\n",
    "def get_gpu_memory_usage():\n",
    "    try:\n",
    "        from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "        nvmlInit()\n",
    "        handle = nvmlDeviceGetHandleByIndex(0)  # Assuming we're using GPU 0\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        return info.used / 1024**2  # Return in MB\n",
    "    except:\n",
    "        return 0  # Return 0 if pynvml is not available\n",
    "\n",
    "# Load dataset\n",
    "def load_imdb_dataset():\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    # Ensure we only use 3000 samples for training and 2000 for testing\n",
    "    train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(3000))\n",
    "    test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(2000))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Compute metrics function for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "def run_lora_finetuning():\n",
    "    \"\"\"\n",
    "    Run LoRA fine-tuning without quantization as a fallback\n",
    "    when bitsandbytes is not available\n",
    "    \"\"\"\n",
    "    method_name = \"lora_finetuning\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Running Method: LoRA Fine-Tuning (Standard)\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    \n",
    "    # Load and prepare datasets\n",
    "    train_dataset, test_dataset = load_imdb_dataset()\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_dataset.map(\n",
    "        lambda examples: tokenize_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    tokenized_test = test_dataset.map(\n",
    "        lambda examples: tokenize_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    # Load the base model\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"roberta-base\",\n",
    "        num_labels=2  # Binary classification\n",
    "    )\n",
    "    \n",
    "    # Define LoRA configuration\n",
    "    lora_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        r=8,  # Rank\n",
    "        lora_alpha=16,  # Alpha scaling\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"query\", \"key\", \"value\"],  # Target attention modules\n",
    "    )\n",
    "    \n",
    "    # Apply LoRA adapters to the model\n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    print(\"Model with LoRA adapters:\")\n",
    "    model.print_trainable_parameters()  # Print % of trainable parameters\n",
    "    \n",
    "    # Setup trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"output/{method_name}\",\n",
    "        eval_strategy=\"epoch\",  # Fixed from eval_strategy\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",  # Disable wandb, tensorboard etc.\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    max_gpu_memory = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Use built-in training loop\n",
    "        trainer.train()\n",
    "            \n",
    "        # Record GPU memory usage\n",
    "        if torch.cuda.is_available():\n",
    "            current_memory = get_gpu_memory_usage()\n",
    "            max_gpu_memory = max(max_gpu_memory, current_memory)\n",
    "            print(f\"GPU Memory after training: {current_memory:.2f} MB\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation Results: {eval_results}\")\n",
    "    \n",
    "    # Record and save statistics\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    stats = {\n",
    "        \"method\": method_name,\n",
    "        \"training_time\": training_time,\n",
    "        \"trainable_parameters\": trainable_params,\n",
    "        \"total_parameters\": total_params,\n",
    "        \"trainable_percentage\": (trainable_params / total_params) * 100,\n",
    "        \"accuracy\": eval_results[\"eval_accuracy\"]\n",
    "    }\n",
    "    \n",
    "    if max_gpu_memory > 0:\n",
    "        stats[\"max_gpu_memory_mb\"] = max_gpu_memory\n",
    "    \n",
    "    print(f\"\\n{method_name} Statistics:\")\n",
    "    print(f\"  Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"  Total Parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable Parameters %: {stats['trainable_percentage']:.2f}%\")\n",
    "    print(f\"  Accuracy: {stats['accuracy']:.4f}\")\n",
    "    if max_gpu_memory > 0:\n",
    "        print(f\"  Max GPU Memory Usage: {max_gpu_memory:.2f} MB\")\n",
    "    \n",
    "    # Save statistics and results\n",
    "    os.makedirs(\"stats\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # Save statistics\n",
    "    with open(f\"stats/{method_name}_stats.txt\", \"w\") as f:\n",
    "        for key, value in stats.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    # Save evaluation results\n",
    "    with open(f\"results/{method_name}_eval.txt\", \"w\") as f:\n",
    "        for key, value in eval_results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    return model, eval_results, stats\n",
    "\n",
    "def run_qlora_finetuning():\n",
    "    \"\"\"\n",
    "    Try to run QLoRA with quantization, falling back to standard LoRA\n",
    "    if bitsandbytes is not available\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if bitsandbytes is properly installed\n",
    "        import bitsandbytes\n",
    "        from transformers import BitsAndBytesConfig\n",
    "        print(f\"bitsandbytes version: {bitsandbytes.__version__}\")\n",
    "        \n",
    "        method_name = \"qlora_finetuning\"\n",
    "        print(f\"\\n{'=' * 50}\")\n",
    "        print(f\"Running Method: QLoRA Fine-Tuning\")\n",
    "        print(f\"{'=' * 50}\")\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "        \n",
    "        # Load and prepare datasets\n",
    "        train_dataset, test_dataset = load_imdb_dataset()\n",
    "        \n",
    "        # Tokenize datasets\n",
    "        tokenized_train = train_dataset.map(\n",
    "            lambda examples: tokenize_function(examples, tokenizer),\n",
    "            batched=True\n",
    "        )\n",
    "        tokenized_test = test_dataset.map(\n",
    "            lambda examples: tokenize_function(examples, tokenizer),\n",
    "            batched=True\n",
    "        )\n",
    "        \n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        \n",
    "        # Configure quantization\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,  # Quantize to 4-bit precision\n",
    "            bnb_4bit_compute_dtype=torch.float16,  # Use float16 for computation\n",
    "            bnb_4bit_quant_type=\"nf4\",  # Normal Float 4\n",
    "            bnb_4bit_use_double_quant=True,  # Use double quantization for more efficiency\n",
    "        )\n",
    "        \n",
    "        # Load the quantized base model\n",
    "        base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            num_labels=2,  # Binary classification\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\"  # Automatically decide device mapping\n",
    "        )\n",
    "        \n",
    "        # Define LoRA configuration for the quantized model\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            r=8,  # Rank\n",
    "            lora_alpha=16,  # Alpha scaling\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"query\", \"key\", \"value\"],  # Target attention modules\n",
    "        )\n",
    "        \n",
    "        # Apply LoRA adapters to the quantized model\n",
    "        model = get_peft_model(base_model, lora_config)\n",
    "        print(\"Model with QLoRA adapters:\")\n",
    "        model.print_trainable_parameters()  # Print % of trainable parameters\n",
    "        \n",
    "        # Setup trainer\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"output/{method_name}\",\n",
    "            eval_strategy=\"epoch\",  # Fixed from eval_strategy\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=3,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            push_to_hub=False,\n",
    "            report_to=\"none\",  # Disable wandb, tensorboard etc.\n",
    "            # Important for 4-bit quantization compatibility\n",
    "            fp16=True,  # Use mixed precision\n",
    "            bf16=False,  # Don't use bfloat16\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_test,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        max_gpu_memory = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Use built-in training loop\n",
    "            trainer.train()\n",
    "                \n",
    "            # Record GPU memory usage\n",
    "            if torch.cuda.is_available():\n",
    "                current_memory = get_gpu_memory_usage()\n",
    "                max_gpu_memory = max(max_gpu_memory, current_memory)\n",
    "                print(f\"GPU Memory after training: {current_memory:.2f} MB\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Training error: {e}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Evaluate the model\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(f\"Evaluation Results: {eval_results}\")\n",
    "        \n",
    "        # Record and save statistics\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        # Count trainable parameters\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        stats = {\n",
    "            \"method\": method_name,\n",
    "            \"training_time\": training_time,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_percentage\": (trainable_params / total_params) * 100,\n",
    "            \"accuracy\": eval_results[\"eval_accuracy\"]\n",
    "        }\n",
    "        \n",
    "        if max_gpu_memory > 0:\n",
    "            stats[\"max_gpu_memory_mb\"] = max_gpu_memory\n",
    "        \n",
    "        print(f\"\\n{method_name} Statistics:\")\n",
    "        print(f\"  Training Time: {training_time:.2f} seconds\")\n",
    "        print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
    "        print(f\"  Total Parameters: {total_params:,}\")\n",
    "        print(f\"  Trainable Parameters %: {stats['trainable_percentage']:.2f}%\")\n",
    "        print(f\"  Accuracy: {stats['accuracy']:.4f}\")\n",
    "        if max_gpu_memory > 0:\n",
    "            print(f\"  Max GPU Memory Usage: {max_gpu_memory:.2f} MB\")\n",
    "        \n",
    "        # Save statistics and results\n",
    "        os.makedirs(\"stats\", exist_ok=True)\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        \n",
    "        # Save statistics\n",
    "        with open(f\"stats/{method_name}_stats.txt\", \"w\") as f:\n",
    "            for key, value in stats.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "        # Save evaluation results\n",
    "        with open(f\"results/{method_name}_eval.txt\", \"w\") as f:\n",
    "            for key, value in eval_results.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "        return model, eval_results, stats\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"bitsandbytes package not found or incompatible version.\")\n",
    "        print(\"Falling back to standard LoRA finetuning without quantization.\")\n",
    "        return run_lora_finetuning()\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error during QLoRA setup: {e}\")\n",
    "        print(\"Falling back to standard LoRA finetuning without quantization.\")\n",
    "        return run_lora_finetuning()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # First, try to install bitsandbytes if it's not available\n",
    "    try:\n",
    "        import bitsandbytes\n",
    "        print(f\"bitsandbytes is already installed (version {bitsandbytes.__version__})\")\n",
    "    except ImportError:\n",
    "        print(\"bitsandbytes not found. Attempting to install...\")\n",
    "        import subprocess\n",
    "        try:\n",
    "            subprocess.check_call([\"pip\", \"install\", \"bitsandbytes>=0.39.0\"])\n",
    "            print(\"bitsandbytes installation successful!\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"Failed to install bitsandbytes. Will use standard LoRA instead of QLoRA.\")\n",
    "    \n",
    "    # Run QLoRA (with fallback to standard LoRA if necessary)\n",
    "    run_qlora_finetuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc5159",
   "metadata": {},
   "source": [
    "Method 4: Adapter Tuning (IA3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from peft import get_peft_model, IA3Config, TaskType\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "# Function to measure GPU memory usage\n",
    "def get_gpu_memory_usage():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)  # Assuming we're using GPU 0\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    return info.used / 1024**2  # Return in MB\n",
    "\n",
    "# Load dataset\n",
    "def load_imdb_dataset():\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    # Use only a subset to speed up training/testing\n",
    "    train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(3000))\n",
    "    test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(2000))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Compute metrics function for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "# Main IA3 finetuning function\n",
    "def run_ia3_finetuning():\n",
    "    method_name = \"ia3_adapter_tuning\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Running Method: IA3 Adapter Tuning\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    # Load and tokenize dataset\n",
    "    train_dataset, test_dataset = load_imdb_dataset()\n",
    "    tokenized_train = train_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    tokenized_test = test_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # Load base model\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "    # Define IA3 configuration with correct module names for RoBERTa\n",
    "    ia3_config = IA3Config(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        target_modules=[\n",
    "            \"self.query\",\n",
    "            \"self.key\", \n",
    "            \"self.value\", \n",
    "            \"output.dense\", \n",
    "            \"intermediate.dense\"\n",
    "        ],\n",
    "        feedforward_modules=[\n",
    "            \"intermediate.dense\", \n",
    "            \"output.dense\"\n",
    "        ],\n",
    "        inference_mode=False\n",
    "    )\n",
    "\n",
    "    # Apply IA3 to model\n",
    "    model = get_peft_model(base_model, ia3_config)\n",
    "    print(\"Model with IA3 adapters:\")\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"output/{method_name}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train and measure GPU memory\n",
    "    max_gpu_memory = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        trainer.train()\n",
    "        if torch.cuda.is_available():\n",
    "            current_memory = get_gpu_memory_usage()\n",
    "            max_gpu_memory = max(max_gpu_memory, current_memory)\n",
    "            print(f\"GPU Memory after training: {current_memory:.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {e}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Evaluation\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Stats collection\n",
    "    training_time = end_time - start_time\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    stats = {\n",
    "        \"method\": method_name,\n",
    "        \"training_time\": training_time,\n",
    "        \"trainable_parameters\": trainable_params,\n",
    "        \"total_parameters\": total_params,\n",
    "        \"trainable_percentage\": (trainable_params / total_params) * 100,\n",
    "        \"accuracy\": eval_results[\"eval_accuracy\"]\n",
    "    }\n",
    "\n",
    "    if max_gpu_memory > 0:\n",
    "        stats[\"max_gpu_memory_mb\"] = max_gpu_memory\n",
    "\n",
    "    # Print stats\n",
    "    print(f\"\\n{method_name} Statistics:\")\n",
    "    print(f\"  Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"  Total Parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable Parameters %: {stats['trainable_percentage']:.2f}%\")\n",
    "    print(f\"  Accuracy: {stats['accuracy']:.4f}\")\n",
    "    if max_gpu_memory > 0:\n",
    "        print(f\"  Max GPU Memory Usage: {max_gpu_memory:.2f} MB\")\n",
    "\n",
    "    # Save stats and results\n",
    "    os.makedirs(\"stats\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "    with open(f\"stats/{method_name}_stats.txt\", \"w\") as f:\n",
    "        for key, value in stats.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    with open(f\"results/{method_name}_eval.txt\", \"w\") as f:\n",
    "        for key, value in eval_results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    return model, eval_results, stats\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    run_ia3_finetuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2208d5",
   "metadata": {},
   "source": [
    "Part 4. Visualization\n",
    "\n",
    "Generate comparative bar charts illustrating:\n",
    "● Accuracy\n",
    "● Training time\n",
    "● Number of trainable parameters\n",
    "● GPU memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbeadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def read_stats_files(directory=\"stats\"):\n",
    "    \"\"\"Read all stats files and combine them into a DataFrame\"\"\"\n",
    "    all_stats = []\n",
    "    \n",
    "    # Find all stats files in the directory\n",
    "    stats_files = glob.glob(f\"{directory}/*_stats.txt\")\n",
    "    \n",
    "    if not stats_files:\n",
    "        print(f\"No stats files found in {directory}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(stats_files)} stats files: {stats_files}\")\n",
    "    \n",
    "    # Read each stats file and extract data\n",
    "    for file_path in stats_files:\n",
    "        stats = {}\n",
    "        method_name = os.path.basename(file_path).replace(\"_stats.txt\", \"\")\n",
    "        stats[\"method\"] = method_name\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if ':' in line:\n",
    "                        key, value = line.strip().split(':', 1)\n",
    "                        key = key.strip()\n",
    "                        value = value.strip()\n",
    "                        \n",
    "                        # Try to convert to numeric if possible\n",
    "                        try:\n",
    "                            if '.' in value:\n",
    "                                stats[key] = float(value)\n",
    "                            else:\n",
    "                                stats[key] = int(value)\n",
    "                        except ValueError:\n",
    "                            stats[key] = value\n",
    "            \n",
    "            all_stats.append(stats)\n",
    "            print(f\"Loaded stats from {file_path}: {stats}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File {file_path} not found\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if all_stats:\n",
    "        return pd.DataFrame(all_stats)\n",
    "    return None\n",
    "\n",
    "def create_visualizations():\n",
    "    \"\"\"Create visualizations comparing the different fine-tuning methods\"\"\"\n",
    "    # Load results data from stats files\n",
    "    df = read_stats_files()\n",
    "    \n",
    "    if df is None or df.empty:\n",
    "        print(\"No valid stats data found. Creating example data for visualization.\")\n",
    "        # Create example data\n",
    "        data = {\n",
    "            'method': ['lora_finetuning', 'qlora_finetuning'],\n",
    "            'accuracy': [0.85, 0.84],\n",
    "            'training_time': [600, 400],\n",
    "            'trainable_parameters': [1000000, 300000],\n",
    "            'trainable_percentage': [5.0, 1.5],\n",
    "            'max_gpu_memory_mb': [4000, 2500]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create output directory for plots\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    \n",
    "    # Create method names for plots with better formatting\n",
    "    df['display_name'] = df['method'].apply(lambda x: x.replace('_finetuning', '').upper())\n",
    "    \n",
    "    # 1. Accuracy plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x='display_name', y='accuracy', data=df, palette='viridis')\n",
    "    plt.title(\"Accuracy Comparison\")\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    \n",
    "    # Set y-limit to focus on differences if values are close\n",
    "    min_acc = df['accuracy'].min() * 0.95\n",
    "    max_acc = df['accuracy'].max() * 1.05\n",
    "    plt.ylim(min_acc, max_acc)\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        ax.annotate(f\"{p.get_height():.4f}\", \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/accuracy_comparison.png\", dpi=300)\n",
    "    \n",
    "    # 2. Training time plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x='display_name', y='training_time', data=df, palette='viridis')\n",
    "    plt.title(\"Training Time Comparison\")\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"Training Time (seconds)\")\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        ax.annotate(f\"{p.get_height():.1f}s\", \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/training_time_comparison.png\", dpi=300)\n",
    "    \n",
    "    # 3. Trainable parameters plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Convert to millions for better readability\n",
    "    df['trainable_parameters_millions'] = df['trainable_parameters'] / 1000000\n",
    "    \n",
    "    ax = sns.barplot(x='display_name', y='trainable_parameters_millions', data=df, palette='viridis')\n",
    "    plt.title(\"Trainable Parameters Comparison\")\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"Trainable Parameters (millions)\")\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        ax.annotate(f\"{p.get_height():.2f}M\", \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/trainable_parameters_comparison.png\", dpi=300)\n",
    "    \n",
    "    # 4. GPU Memory Usage\n",
    "    if 'max_gpu_memory_mb' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.barplot(x='display_name', y='max_gpu_memory_mb', data=df, palette='viridis')\n",
    "        plt.title(\"GPU Memory Usage Comparison\")\n",
    "        plt.xlabel(\"Method\")\n",
    "        plt.ylabel(\"GPU Memory (MB)\")\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for i, p in enumerate(ax.patches):\n",
    "            ax.annotate(f\"{p.get_height():.1f} MB\", \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"plots/gpu_memory_comparison.png\", dpi=300)\n",
    "    \n",
    "    # 5. Combined plot showing all metrics normalized\n",
    "    # Normalize data for easy comparison\n",
    "    metrics = ['accuracy', 'training_time', 'trainable_parameters']\n",
    "    if 'max_gpu_memory_mb' in df.columns:\n",
    "        metrics.append('max_gpu_memory_mb')\n",
    "    \n",
    "    # Create a new DataFrame with normalized values\n",
    "    df_norm = pd.DataFrame()\n",
    "    df_norm['method'] = df['display_name']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric == 'accuracy':  # For accuracy, higher is better\n",
    "            df_norm[metric] = df[metric] / df[metric].max()\n",
    "        else:  # For other metrics, lower is better\n",
    "            if df[metric].max() > 0:  # Avoid division by zero\n",
    "                df_norm[metric] = 1 - (df[metric] / df[metric].max())\n",
    "            else:\n",
    "                df_norm[metric] = 0\n",
    "    \n",
    "    # Plot combined metrics\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    df_melted = pd.melt(df_norm, id_vars=['method'], var_name='Metric', value_name='Normalized Score')\n",
    "    \n",
    "    # Format metric names for the legend\n",
    "    metric_names = {\n",
    "        'accuracy': 'Accuracy (higher is better)',\n",
    "        'training_time': 'Training Time (lower is better)',\n",
    "        'trainable_parameters': 'Trainable Parameters (lower is better)',\n",
    "        'max_gpu_memory_mb': 'GPU Memory Usage (lower is better)'\n",
    "    }\n",
    "    df_melted['Metric'] = df_melted['Metric'].map(lambda x: metric_names.get(x, x))\n",
    "    \n",
    "    ax = sns.barplot(x='method', y='Normalized Score', hue='Metric', data=df_melted)\n",
    "    plt.title(\"Normalized Comparison of All Metrics\")\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"Normalized Score (higher is better)\")\n",
    "    plt.legend(title='Metric', loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/combined_normalized_comparison.png\", dpi=300)\n",
    "    \n",
    "    print(\"All visualizations have been saved to the 'plots' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_visualizations()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
